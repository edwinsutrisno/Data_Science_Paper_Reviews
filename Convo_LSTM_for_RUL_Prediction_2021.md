**A Paper Review on "Deep-Convolution-Based LSTM Network for Remaining Useful Life Prediction" (Meng Ma and Zhu Mao, IEEE Transactions on Industrial Informatics, Vol. 17, No. 3, March 2021)**

*by Edwin Sutrisno, May 2021.*

---

The paper demonstrates the application of a new construct of deep learning model which combines convolutional feature with an LSTM. The argument behind hybridizing the LSTM with CNN is that, in some cases, this setup will allow simpler feature engineering (i.e. data pre-processing) and produce more accurate prediction when analyzing data that has both temporal and spatial dependency. 

An example given in the paper is the case of analyzing vibration data to predict the remaining useful life (RUL) of bearing life test data. In traditional ways of modeling vibration, accelerometer signal is extracted into statistical features such as RMSE, skewness, power spectrum, kurtosis and others and fed into a predictive model. This method can involve many features and rely on the personâ€™s judgment of what features to include. 

Another popular and powerful way of analyzing vibration data is by visually inspecting a 2D time-frequency feature plot. Time-frequency plot comes in many flavors like cross-spectrograms, Wigner-Ville, and others, but the point is that these 2D images comprise all the information that traditional statistical feature extractions try to extract. So, instead of spending effort into feature engineering, we ask the model to analyze these images and figure out the features automatically. In predicting the RUL of bearings, the model must forecast the future pattern of damage. In this case, it is the image of unhealthy time-frequency features. As in many forecasting applications, the past data is an important component in predicting the future, and this is where the LSTM plays a key role in the model. 

My personal take on this paper that it offers a clever idea of fusing two deep-learning models. It may help in specific cases where we have image recognition problem that has a temporal aspect. The paper gave some theoretical concept on the model construct but no practical implementation details that we can immediately try to code with. The demonstrated example was weak with respect to model development best practices. They used only 2 bearings tested in a lab, run from new to failure, and the model was trained and tested on both bearings instead of using a left-out testing sample. I understand that testing is expensive, but 2 samples seems a bit too low to offer conclusions. Finally, I think it is a technique that is worth trying. The idea is theoretically sound, but implementation details is the key to success.
